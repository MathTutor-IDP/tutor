{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "a3a9bce0-0691-434f-b8b3-8d6eca17e441",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transform data from pickle to jsonl\n",
    "import pickle\n",
    "with open(\"finetune_part2.pkl\",\"rb\") as f:\n",
    "    data = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "dc39eb4a-ded9-4ae7-9e7c-369bb6a7f00e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.datasets.MATH import MATHRecord,MATH\n",
    "import json\n",
    "\n",
    "mathDataset = MATH(\"./data/math.jsonl\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "313ce3f6-4d31-4b1c-a21a-72268b68bac8",
   "metadata": {},
   "outputs": [],
   "source": [
    "system_promt = \"\"\"\n",
    "You are a chatbot that finds and classifies the error in the students solution.\n",
    "There are only two possible outcome for the questions: LOGICAL and CONCENTRATION.\n",
    "If the mistake is made in reasoning or in the application of a rule, even though the basic operations are performed correctly the error type is LOGICAL.\n",
    "If the incorrect result comes from a lapse in attention leads to an oversight or a careless mistake in the calculations or steps, or not using basic preconditions given in the question properly error type is CONCENTRATION.\n",
    "Do not repeat any given information.\n",
    "Explain the error and determine the error type.\n",
    "State the error type explicitly in the end.\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "new_sys_prompt = \"\"\"\n",
    "You are a chatbot that finds and classifies the error in the students solution.\n",
    "\n",
    "Use the following step-by-step instructions to respond to the user inputs.\n",
    "\n",
    "There are only two possible outcome for the questions: LOGICAL and CONCENTRATION.\n",
    "If the mistake is made in reasoning or in the application of a rule, even though the basic operations are performed correctly the error type is LOGICAL.\n",
    "If the incorrect result comes from a lapse in attention leads to an oversight or a careless mistake in the calculations or steps, or not using basic preconditions given in the question properly error type is CONCENTRATION.\n",
    "Do not repeat any given information.\n",
    "Explain the error and determine the error type.\n",
    "State the error type explicitly in the end.\n",
    "\n",
    "\n",
    "\n",
    "Step 1:\n",
    "By comparing the student´s solution and the real solution find the error made and explain what is made wrong.\n",
    "\n",
    "Step 2:\n",
    "Decide the type of error in students solutions in the set of (LOGICAL, CONCENTRATION) \n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "0ae0c799-dd82-408d-abfb-f6cbbfea73dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create training file from dataset\n",
    "dict_list = []\n",
    "\n",
    "for val in data:\n",
    "    error_exp = val[\"error_explanation\"]\n",
    "    incorrect_sol = val[\"incorrect_solution\"]\n",
    "    error_type = val[\"error_type\"]\n",
    "    question = val[\"record\"].question\n",
    "    true_solution = mathDataset.records[val[\"record\"].id].solution\n",
    "    if type(true_solution) == list:\n",
    "        true_solution = \"\".join(str(sol) for sol in true_solution)\n",
    "    step_dict = {\"messages\": [{\"role\": \"system\", \"content\": system_promt},\n",
    "                  {\"role\": \"user\", \"content\": \"QUESTION: \" + question +\"\\nCORRECT SOLUTION: \"+ true_solution +\"\\nSTUDENT'S SOLUTION: \" + incorrect_sol},\n",
    "                  {\"role\": \"assistant\", \"content\": \"ERROR EXPLANATION: \"+ error_exp +\"\\nERROR TYPE: \" + error_type}]}\n",
    "    dict_list.append(step_dict)\n",
    "\n",
    "with open(\"data.jsonl\", 'w') as f:\n",
    "    for item in dict_list:\n",
    "        f.write(json.dumps(item) + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "67da821c-2222-4543-857e-2949d3584966",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import dotenv\n",
    "import os\n",
    "\n",
    "from openai import OpenAI\n",
    "\n",
    "dotenv.load_dotenv()\n",
    "API_KEY = os.getenv(\"OPENAI_API_KEY\", \"\")\n",
    "client = OpenAI()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d32dcb8-a43a-41ae-98ab-bc84e21fd293",
   "metadata": {},
   "outputs": [],
   "source": [
    "fine_tune = client.files.create(\n",
    "    file=open(\"data.jsonl\", \"rb\"),\n",
    "    purpose=\"fine-tune\")\n",
    "while True:\n",
    "    finetune_file_handle = client.files.retrieve(file_id=fine_tune.id)\n",
    "    print(finetune_file_handle.status)\n",
    "    if finetune_file_handle.status == \"processed\":\n",
    "        break\n",
    "    time.sleep(60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b62a5f7-914e-446a-9cce-a21c239ac68f",
   "metadata": {},
   "outputs": [],
   "source": [
    "validation = client.files.create(\n",
    "    file=open(\"validation.jsonl\", \"rb\"),\n",
    "    purpose=\"fine-tune\")\n",
    "while True:\n",
    "    validation_file_handle = client.files.retrieve(file_id=validation.id)\n",
    "    print(validation_file_handle.status)\n",
    "    if validation_file_handle.status == \"processed\":\n",
    "        break\n",
    "    time.sleep(60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1f77963-9a18-4a35-bf35-52fd25c59fb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# With Validation\n",
    "job = client.fine_tuning.jobs.create(\n",
    "    training_file=fine_tune.id,\n",
    "    validation_file=validation.id,\n",
    "    model=\"gpt-3.5-turbo\",\n",
    "    hyperparameters={\n",
    "    \"n_epochs\":3\n",
    "    }\n",
    "    )\n",
    "print(job.id)\n",
    "print(\"DONT LOSE THIS\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33cbd985-af09-4744-8301-1707d4944bff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Without Validation\n",
    "job = client.fine_tuning.jobs.create(\n",
    "    training_file=fine_tune.id,\n",
    "    model=\"gpt-3.5-turbo\",\n",
    "    hyperparameters={\n",
    "    \"n_epochs\":7\n",
    "    }\n",
    "    )\n",
    "print(job.id)\n",
    "print(\"DONT LOSE THIS\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6dbda13d-db1a-437a-85f4-898aef49da32",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Basic\n",
    "job = client.fine_tuning.jobs.create(\n",
    "    training_file=fine_tune.id,\n",
    "    model=\"ft:gpt-3.5-turbo-0125:tum-sot-hctl::9VgFsUc6\"\n",
    "    )\n",
    "print(job.id)\n",
    "print(\"DONT LOSE THIS\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6055b1f-ddad-452b-b1fc-57b83ccb655d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check finetuning condition\n",
    "job_handle = client.fine_tuning.jobs.retrieve(job.id)\n",
    "print(\"Job status: \", job_handle.status)\n",
    "print(job_handle)\n",
    "print(job_handle.fine_tuned_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62940a45-b268-424e-8f17-45de112ab079",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Auto Checker\n",
    "while True:\n",
    "    job_handle = client.fine_tuning.jobs.retrieve(job.id)\n",
    "    if job_handle.status == \"succeeded\":\n",
    "        break\n",
    "    print(\"Job status: \", job_handle.status)\n",
    "    time.sleep(60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b20a127e-8672-4102-83c7-8e42702c49ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "job_handle = client.fine_tuning.jobs.retrieve(job.id)\n",
    "print(job_handle.fine_tuned_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95eb592e-1e27-4adb-8e99-d300010e5d58",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save model name\n",
    "with open(\"model_id.txt\", \"w\") as file:\n",
    "    file.write(job_handle.fine_tuned_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "c6d3b290-a8b1-469e-8258-990f23aa269f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "fine_tuning_list = client.fine_tuning.jobs.list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "a40d1f59-8dc5-4b32-b063-3e1f20b91e1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "saved_models = [\"ft:gpt-3.5-turbo-0125:tum-sot-hctl::9T5ZS7eP\",\"ft:gpt-3.5-turbo-0125:tum-sot-hctl::9Quieny6\",\"ft:gpt-3.5-turbo-0125:tum-sot-hctl::9MisNHwy\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "7da1278c-3a2f-4112-a3e8-63ea55ebe0dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "selected = []\n",
    "for fine_tune_job in fine_tuning_list.data:\n",
    "    if fine_tune_job.fine_tuned_model in saved_models:\n",
    "        selected.append(fine_tune_job)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2ef197d-8333-49eb-b3a7-956bad70f9a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get metrics \n",
    "checkpoints = client.fine_tuning.jobs.checkpoints.list(job.id).data\n",
    "checkpoints[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "d3a52d50-6529-4055-a5f6-56894a6e8e94",
   "metadata": {},
   "outputs": [],
   "source": [
    "losses = []\n",
    "steps = []\n",
    "for check in checkpoints:\n",
    "    met = check.metrics\n",
    "    losses.append(met.train_loss)\n",
    "    steps.append(met.step)\n",
    "losses.reverse()\n",
    "steps.reverse()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09e16fdb-fbf3-47d1-8e42-5aaf1e85ecb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.style.use({\"lines.linestyle\": \"solid\", \"lines.linewidth\": 1})\n",
    "plt.plot(steps, losses, color=\"#47c984\")\n",
    "\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
